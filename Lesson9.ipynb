{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "train_input_data = [[10, 7], [5, 4], [8, 3], [2, 8], [4, 8]]\n",
    "train_output_data = [[97], [71], [74], [78], [90]]\n",
    "\n",
    "NUM_TRAIN_EXAMPLES = len(train_input_data)\n",
    "\n",
    "NUM_FEATURES = len(train_input_data[0])\n",
    "\n",
    "test_input_data = [[9, 1], [6, 8], [1, 7], [5, 3], [7, 6]]\n",
    "test_output_data = [[68], [95], [65], [70], [82]]\n",
    "\n",
    "EPOCHS = 10000\n",
    "NUM_HIDDEN_LAYER_NEURONS = 3\n",
    "LEARNING_RATE = 2.0\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    input = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "    output = tf.placeholder(dtype=tf.float32)\n",
    "\n",
    "    train_data = {input: train_input_data, output: train_output_data}\n",
    "    test_data = {input: test_input_data, output: test_output_data}\n",
    "\n",
    "    max_input = tf.reduce_max(input, 0)\n",
    "\n",
    "    normalized_input = input / max_input\n",
    "\n",
    "    max_output = tf.reduce_max(output)\n",
    "    normalized_output = output / max_output\n",
    "\n",
    "    num_neurons_1 = NUM_FEATURES\n",
    "    num_neurons_2 = NUM_HIDDEN_LAYER_NEURONS\n",
    "    num_neurons_3 = 1\n",
    "\n",
    "    weights_1 = tf.Variable(tf.random_normal([num_neurons_1, num_neurons_2]))\n",
    "\n",
    "    bias_1 = tf.Variable(tf.random_normal([num_neurons_2]))\n",
    "    weighted_sums_1 = tf.matmul(normalized_input, weights_1) + bias_1\n",
    "\n",
    "    activation_1 = tf.sigmoid(weighted_sums_1)\n",
    "\n",
    "    weights_2 = tf.Variable(tf.random_normal([num_neurons_2, num_neurons_3]))\n",
    "    bias_2 = tf.Variable(tf.random_normal([num_neurons_3]))\n",
    "    weighted_sums_2 = tf.matmul(activation_1, weights_2) + bias_2\n",
    "    activation_2 = tf.sigmoid(weighted_sums_2)\n",
    "\n",
    "    loss = tf.reduce_sum((activation_2 - normalized_output)**2) / NUM_TRAIN_EXAMPLES\n",
    "\n",
    "    train_step = tf.train.GradientDescentOptimizer(learning_rate=LEARNING_RATE).minimize(loss)\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        while sess.run(loss, feed_dict = feed_dict) > 0.001:\n",
    "            sess.run(train_step, feed_dict = train_data)\n",
    "            \n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
